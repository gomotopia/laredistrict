{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from gerrychain import (GeographicPartition, Partition, Graph, MarkovChain,\n",
    "                        proposals, updaters, constraints, accept, Election)\n",
    "from gerrychain.proposals import recom\n",
    "from functools import partial\n",
    "import pandas as pd \n",
    "from gerrychain.tree import recursive_tree_part\n",
    "from gerrychain.updaters import Tally, cut_edges\n",
    "from gerrychain.metrics import efficiency_gap, mean_median, partisan_bias, polsby_popper, partisan_gini\n",
    "import geopandas\n",
    "import csv, json\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_districts = 39\n",
    "sen_target_pop = sum(laprec['TotalPop'])/39\n",
    "population_column = \"TotalPop\"\n",
    "tolerance = .04\n",
    "\n",
    "lp = Graph.from_geodataframe(laprec, ignore_errors=True)\n",
    "\n",
    "#update with elections in your gdf\n",
    "elections = [\n",
    "    Election('2020_Pres',{'Democratic':'Dem_2020_Pres','Republican':'Rep_2020_Pres'}),\n",
    "    Election('2019_Gov',{'Democratic':'Dem_2019_Gov','Republican':'Rep_2019_Gov'}),\n",
    "    Election('2019_AG',{'Democratic':'Dem_2019_AG','Republican':'Rep_2019_AG'}),\n",
    "    Election('2019_Gov.1',{'Democratic':'Dem_2019_Gov.1','Republican':'Rep_2019_Gov.1'}),\n",
    "    Election('2016_Pres',{'Democratic':'Dem_2016_Pres','Republican':'Rep_2016_Pres'}),\n",
    "    Election('2016_Sen',{'Democratic':'Dem_2016_Sen','Republican':'Rep_2016_Sen'}),\n",
    "    Election('2016_Sen.1',{'Democratic':'Dem_2016_Sen.1','Republican':'Rep_2016_Sen.1'})\n",
    "    ]\n",
    "\n",
    "num_elections = len(elections)\n",
    "\n",
    "election_names = [i.name for i in elections]\n",
    "election_columns = [[i.parties_to_columns['Democratic'], i.parties_to_columns['Republican']] for i in elections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laprec = geopandas.read_file(\"G:\\My Drive\\SFK Maps\\Final Chain Data\\laprecfinal.geojson\")\n",
    "laprec = laprec.to_crs('epsg:3452')\n",
    "\n",
    "#laprec.to_file(\"G:\\\\My Drive\\\\SFK Maps\\\\Oct 21\\\\laprecfinal.geojson\", driver='GeoJSON')  \n",
    "#laprec.to_file(\"G:\\\\My Drive\\\\SFK Maps\\\\Oct 21\\\\laprecfinal.geojson\", driver='GeoJSON')\n",
    "#laprec.to_csv(\"G:\\My Drive\\SFK Maps\\Check of percmetrics\\laprec.csv\")\n",
    "\n",
    "# Population updater, for computing how close to equality the district\n",
    "# populations are. \"TOTPOP\" is the population column from our shapefile.\n",
    "my_updaters = {\"population\": updaters.Tally(\"TotalPop\", alias=\"population\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_splits(partition): \n",
    "    laprec[\"current\"] = laprec.index.map(dict(partition.assignment))\n",
    "    splits = sum(laprec.groupby(\"COUNTYFP10\")[\"current\"].nunique() > 1)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]:\n",
    "\n",
    "\n",
    "# Election updaters, for computing election results using the vote totals\n",
    "# from our shapefile.\n",
    "election_updaters = {election.name: election for election in elections}\n",
    "\n",
    "my_updaters.update(election_updaters)\n",
    "\n",
    "sen_partition = GeographicPartition(lp, assignment=\"sen_seed\", updaters=my_updaters)\n",
    "\n",
    "sencompactness_bound = constraints.UpperBound(\n",
    "    lambda p: len(p[\"cut_edges\"]),\n",
    "    2*len(sen_partition[\"cut_edges\"])\n",
    ")\n",
    "\n",
    "senpop_constraint = constraints.within_percent_of_ideal_population(sen_partition, 0.05)\n",
    "\n",
    "\n",
    "senproposal = partial(recom,\n",
    "                   pop_col=\"TotalPop\",\n",
    "                   pop_target=sen_target_pop,\n",
    "                   epsilon=0.04,\n",
    "                   node_repeats=2\n",
    "                  )\n",
    "senchain = MarkovChain(\n",
    "    proposal=senproposal,\n",
    "    constraints=[\n",
    "        senpop_constraint,\n",
    "        sencompactness_bound\n",
    "    ],\n",
    "    accept=accept.always_accept,\n",
    "    initial_state=sen_partition,\n",
    "    total_steps=50000\n",
    ")\n",
    "\n",
    "unique_label = \"GEOID20\"\n",
    "pop_col = \"TotalPop\"\n",
    "district_col = \"sen_seed\"\n",
    "county_col = \"COUNTYFP10\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percmetrics(partnum, partition):\n",
    "    global laprec\n",
    "    laprec[\"current\"] = laprec.index.map(dict(partition.assignment))\n",
    "    distpop = laprec.groupby([\"current\"])[\"Total_2020_VAP\"].sum()\n",
    "    dempop = laprec.groupby([\"current\"])[\"Total_2016-2020_Comp\"].sum()\n",
    "    dpdf = pandas.concat([distpop,dempop], axis=1)\n",
    "    dpdf = dpdf.rename(columns={\"Total_2020_VAP\":\"temppop\", \"Total_2016-2020_Comp\":\"dempop\"})\n",
    "    laprec = laprec.merge(dpdf, how = \"left\", left_on=\"current\", right_on = dpdf.index)\n",
    "    laprec[\"wgtav\"] = laprec[\"Total_2020_VAP\"] / laprec[\"temppop\"]\n",
    "    laprec['dwgt'] = laprec[\"Total_2016-2020_Comp\"] / laprec[\"dempop\"]\n",
    "    laprec[\"BlkPct\"] = laprec[\"Black_2020_VAP\"] /  laprec[\"Total_2020_VAP\"] \n",
    "    laprec[\"MinPct\"] = (laprec[\"Total_2020_VAP\"] - laprec[\"White_2020_VAP\"] ) /  laprec[\"Total_2020_VAP\"] \n",
    "    laprec[\"DemPct\"] = laprec[\"Dem_2016-2020_Comp\"] / laprec[\"Total_2016-2020_Comp\"] \n",
    "    laprec[\"BlkPctW\"] = laprec[\"BlkPct\"] * laprec[\"wgtav\"]\n",
    "    laprec[\"MinPctW\"] = laprec[\"MinPct\"] * laprec[\"wgtav\"]\n",
    "    laprec[\"DemPctW\"] = laprec[\"DemPct\"] * laprec[\"dwgt\"]\n",
    "    DistDemPct = laprec.groupby([\"current\"])[\"DemPctW\"].sum()\n",
    "    DistMinPct = laprec.groupby([\"current\"])[\"MinPctW\"].sum()\n",
    "    DistBlkPct = laprec.groupby([\"current\"])[\"BlkPctW\"].sum()\n",
    "    DistDemPct = pandas.concat([DistDemPct, DistMinPct, DistBlkPct], axis=1)\n",
    "    DistDemPctD = DistDemPct.to_dict()\n",
    "    findict = {partnum: DistDemPctD}\n",
    "    del(laprec[\"temppop\"])\n",
    "    del(laprec[\"dempop\"])\n",
    "    return findict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "pop_vec = []\n",
    "cut_vec = []\n",
    "votes = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "mms = []\n",
    "egs = []\n",
    "hmss = []\n",
    "pgs =[]\n",
    "pbs = []\n",
    "splits = []\n",
    "pcents = []\n",
    "\n",
    "f=  open(\"G:\\\\My Drive\\\\SFK Maps\\\\Final Chain Data\\\\Senate\\\\Partitions\\\\tracker.txt\", \"a+\")\n",
    "\n",
    "for partnum, part in enumerate(senchain):\n",
    "    \n",
    "    percd =  percmetrics(partnum,part)\n",
    "    \n",
    "    dct = 0\n",
    "    mmct = 0\n",
    "    dem = 0\n",
    "    \n",
    "    \n",
    "    for key in percd[partnum]['DemPctW']:\n",
    "        if percd[partnum]['DemPctW'][key] >= 0.5:\n",
    "            dem += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    for key in percd[partnum]['DemPctW']:\n",
    "        if 0.45 <= percd[partnum]['DemPctW'][key] <= 0.55:\n",
    "            dct += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    for key in percd[partnum]['MinPctW']:\n",
    "        if percd[partnum]['MinPctW'][key] >= 0.50:\n",
    "            mmct += 1\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    if dem >= 9 and mmct >= 9 and dct >= 5 :\n",
    "        pcents.append(percd)\n",
    "        sens = []\n",
    "        g = list(part.graph.nodes)\n",
    "        for y in g:\n",
    "            tt = []\n",
    "            h = part.assignment[y]\n",
    "            tt.append(y)\n",
    "            tt.append(h)\n",
    "            sens.append(tt)\n",
    "        \n",
    "        sensdf = pandas.DataFrame(sens)\n",
    "        sensdf.to_csv(\"G:\\\\My Drive\\\\SFK Maps\\\\Final Chain Data\\\\Senate\\\\Partitions\\\\\" +\"partassgn\"+ str(partnum)+ \".csv\") \n",
    "    \n",
    "        splits.append(num_splits(part))\n",
    "    \n",
    "        pop_vec.append(sorted(list(part[\"population\"].values())))\n",
    "        cut_vec.append(len(part[\"cut_edges\"]))\n",
    "        mms.append([])\n",
    "        egs.append([])\n",
    "        hmss.append([])\n",
    "        pgs.append([])\n",
    "        pbs.append([])\n",
    "        \n",
    "        for elect in range(num_elections):\n",
    "            votes[elect].append(sorted(part[election_names[elect]].percents(\"Democratic\")))\n",
    "            mms[-1].append(mean_median(part[election_names[elect]]))\n",
    "            egs[-1].append(efficiency_gap(part[election_names[elect]]))\n",
    "            pgs[-1].append(partisan_gini(part[election_names[elect]]))\n",
    "            pbs[-1].append(partisan_bias(part[election_names[elect]]))\n",
    "            hmss[-1].append(part[election_names[elect]].wins(\"Democratic\"))\n",
    "        print(partnum, mmct, dem, dct,\"!!!!!\")\n",
    "        f.write(str(partnum) +\" \"+ str(mmct) +\" \"+ str(dem) +\" \"+ str(dct)+\" \"+ \"\\n\")\n",
    "    else:\n",
    "        print(partnum, mmct,dem, dct)\n",
    "        \n",
    "f.close()\n",
    "\n",
    "# In[6]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c64bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmspd = pd.DataFrame(mms)\n",
    "egspd = pd.DataFrame(egs)\n",
    "pgspd = pd.DataFrame(pgs)\n",
    "pbspd = pd.DataFrame(pbs)\n",
    "hmsspd = pd.DataFrame(hmss)\n",
    "splpd = pd.DataFrame(splits)\n",
    "compctpd = pd.DataFrame(compct)\n",
    "\n",
    "mmspd = mmspd.rename(columns={0: \"20Pres_mms\",1: \"19Gov_mms\",2: \"19AG_mms\",3: \"19Gov_1_mms\",4: \"16Pres_mms\",5: \"16sen_mms\",6: \"16_sen_1_mms\"})\n",
    "pgspd = pgspd.rename(columns={0: \"20Pres_pgs\",1: \"19Gov_pgs\",2: \"19AG_pgs\",3: \"19Gov_1_pgs\",4: \"16Pres_pgs\",5: \"16sen_pgs\",6: \"16_sen_1_pgs\"})\n",
    "pbspd = pbspd.rename(columns={0: \"20Pres_pbs\",1: \"19Gov_pbs\",2: \"19AG_pbs\",3: \"19Gov_1_pbs\",4: \"16Pres_pbs\",5: \"16sen_pbs\",6: \"16_sen_1_pbs\"})\n",
    "egspd = mmspd.rename(columns={0: \"20Pres_egs\",1: \"19Gov_egs\",2: \"19AG_egs\",3: \"19Gov_1_egs\",4: \"16Pres_egs\",5: \"16sen_egs\",6: \"16_sen_1_egs\"})\n",
    "hmsspd = hmsspd.rename(columns={0: \"20Pres_hmss\",1: \"19Gov_hmss\",2: \"19AG_hmss\",3: \"19Gov_1_hmss\",4: \"16Pres_hmss\",5: \"16sen_hmss\",6: \"16_sen_1_hmss\"})\n",
    "splpd = splpd.rename(columns={0: \"ParishSplits\"})\n",
    "\n",
    "findf = pandas.concat([compctpd, mmspd,hmsspd,pgspd,pbspd,splpd],axis = 1)\n",
    "\n",
    "\n",
    "findf = findf.rename(columns={0: \"ChainNum\", 1: \"CompDist\",2: \"DemMaj\",3: \"NonPckedBlck\",4: \"BlckMaj\",5: \"NonPckedMM\",6: \"MM\"})\n",
    "\n",
    "#findf.to_csv(\"G:\\My Drive\\SFK Maps\\Final Chain Data\\lasen.csv\")\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "#laprec.to_csv(\"G:\\My Drive\\SFK Maps\\Final Chain Data\\laprec.csv\")\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "findf.to_csv(\"G:\\\\My Drive\\\\SFK Maps\\\\Final Chain Data\\\\Senate\\\\lasen.csv\")\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
