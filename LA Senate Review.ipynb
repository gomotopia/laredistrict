{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note! This was not tested completely before submission. Small edits may be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from gerrychain import (GeographicPartition, Partition, Graph, MarkovChain,\n",
    "                        proposals, updaters, constraints, accept, Election)\n",
    "from gerrychain.proposals import recom\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from gerrychain.tree import recursive_tree_part\n",
    "from gerrychain.updaters import Tally, cut_edges\n",
    "from gerrychain.metrics import efficiency_gap, mean_median, partisan_bias, polsby_popper, partisan_gini\n",
    "import geopandas as gpd\n",
    "import csv, json\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ryan/Documents/LARedistrict'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Input Files and Generate Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laprec = geopandas.read_file(\"G:\\My Drive\\SFK Maps\\Final Chain Data\\laprecfinal.geojson\")\n",
    "laprec = laprec.to_crs('epsg:3452')\n",
    "\n",
    "#laprec.to_file(\"G:\\\\My Drive\\\\SFK Maps\\\\Oct 21\\\\laprecfinal.geojson\", driver='GeoJSON')\n",
    "#laprec.to_csv(\"G:\\My Drive\\SFK Maps\\Check of percmetrics\\laprec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "laprec = gpd.read_file(\"Gerry/laprecfinal.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laprec.columns # Read Column Names laprec[\"Black_2020_VAP\"]\n",
    "laprec[\"Minority_2020_VAP\"] = (laprec[\"Hispanic_2020_VAP\"] + laprec[\"Black_2020_VAP\"] +\n",
    "                               laprec[\"Asian_2020_VAP\"] + laprec[\"Native_2020_VAP\"] \n",
    "                               laprec[\"Pacific_2020_VAP\"])\n",
    "laprec[\"NonMinority_2020_VAP\"] = laprec[\"Total_2020_VAP\"] - laprec[\"Minority_2020_VAP\"]\n",
    "laprec[\"NonDem_2016-2020_Comp\"] = laprec[\"Total_2016-2020_Comp\"] - laprec[\"Dem_2016-2020_Comp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Up laprec\n",
    "\n",
    "laprec = laprec[[\"Minority_2020_VAP\", \"NonMinority_2020_VAP\", \"NonDem_2016-2020_Comp\"]]\n",
    "\n",
    "#laprec.to_file(\"G:\\\\My Drive\\\\SFK Maps\\\\Oct 21\\\\laprecfinal.geojson\", driver='GeoJSON')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "lp = Graph.from_geodataframe(laprec, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEN_DISTRICTS = 39\n",
    "SEN_TARGET_POP = sum(laprec['TotalPop'])/39\n",
    "POPULATION_COLUMN = \"TotalPop\"\n",
    "TOLERANCE = .04\n",
    "UNIQUE_LABEL = \"GEOID20\"\n",
    "POP_COL = POPULATION_COLUMN\n",
    "DISTRICT_COL = \"sen_seed\"\n",
    "COUNTY_COL = \"COUNTYFP10\"\n",
    "\n",
    "PASSIGN_FILE = f\"G:\\\\My Drive\\\\SFK Maps\\\\Final Chain Data\\\\Senate\\\\Partitions\\\\partassgn{}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElectionNames = ['2020_Pres', '2019_Gov', '2019_AG', '2019_Gov.1', '2016_Pres', '2016_Sen', '2016_Sen.1']\n",
    "Elections = [Election(name, {'Democratic':f'Dem_{name}','Republican':f'Rep_{name}'}) for name in ElectionNames]\n",
    "# num_elections = len(elections)\n",
    "# election_columns = [[i.parties_to_columns['Democratic'], i.parties_to_columns['Republican']] for i in elections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can apply Elections' built in percentages function to produce percentages for Demographics\n",
    "\n",
    "DemoElections = [\n",
    "    Election(\"Black_VAP_20\", {'Black':'Black_2020_VAP','NonBlack':'NonBlack_2020_VAP'}),\n",
    "    Election(\"Min_VAP_20\", {'Minority':'Minority_2020_VAP','NonMinority':'NonBlack_2020_VAP'}),\n",
    "    Election(\"Black_VAP_20\", {'Black':'Black_2020_VAP','NonBlack':'NonBlack_2020_VAP'}),\n",
    "    Election(\"Comp_Dems\", {'Democrat':'Dem_2016-2020_Comp','NonDemocrat':'NonDem_2016-2020_Comp'}),\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Updaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_splits(partition): \n",
    "    laprec[\"current\"] = laprec.index.map(dict(partition.assignment))\n",
    "    splits = sum(laprec.groupby(\"COUNTYFP10\")[\"current\"].nunique() > 1)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population updater, for computing how close to equality the district\n",
    "# populations are. \"TOTPOP\" is the population column from our shapefile.\n",
    "my_updaters = {\"population\": updaters.Tally(\"TotalPop\", alias=\"population\"),\n",
    "               \"Total_2020_VAP\": updaters.Tally(\"Total_2020_VAP\"),\n",
    "               \n",
    "               # Sample Extra Other Updaters\n",
    "               # \"Total_2020_VAP\": updaters.Tally(\"Total_2020_VAP\"),\n",
    "               # \"Total_2016-2020_Comp\": updaters.Tally(\"Total_2016-2020_Comp\")   \n",
    "              }\n",
    "\n",
    "# Election updaters, for computing election results using the vote totals\n",
    "# from our shapefile.\n",
    "\n",
    "all_elections = Elections + DemoElections\n",
    "all_updaters = {election.name: election for election in all_elections}\n",
    "my_updaters.update(all_updaters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_partition = GeographicPartition(lp, assignment=\"sen_seed\", updaters=my_updaters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounds and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sencompactness_bound = constraints.UpperBound(\n",
    "    lambda p: len(p[\"cut_edges\"]),\n",
    "    2*len(sen_partition[\"cut_edges\"])\n",
    ")\n",
    "\n",
    "# Not needed as population is bounded by 'epsilon' in recom function?\n",
    "senpop_constraint = constraints.within_percent_of_ideal_population(sen_partition, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposal and Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senproposal = partial(recom,\n",
    "                   pop_col=\"TotalPop\",\n",
    "                   pop_target=sen_target_pop,\n",
    "                   epsilon=0.04,\n",
    "                   node_repeats=2\n",
    "                  )\n",
    "\n",
    "senchain = MarkovChain(\n",
    "    proposal=senproposal,\n",
    "    constraints=[\n",
    "        #? senpop_constraint,\n",
    "        sencompactness_bound\n",
    "    ],\n",
    "    accept=accept.always_accept,\n",
    "    initial_state=sen_partition,\n",
    "    total_steps=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percmetrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Percmetrics Function\n",
    "\n",
    "# # partnum is id of each new Partition \n",
    "# # part is each new partition \n",
    "# def percmetrics(partnum, part):\n",
    "    \n",
    "#     # global laprec\n",
    "    \n",
    "#     laprec[\"current\"] = laprec.index.map(dict(part.assignment))\n",
    "    \n",
    "#     # Originally Returns pd.Series:\n",
    "#     # distpop = laprec.groupby([\"current\"])[\"Total_2020_VAP\"].sum()\n",
    "#     # dempop = laprec.groupby([\"current\"])[\"Total_2016-2020_Comp\"].sum()\n",
    "    \n",
    "#     distpop = pd.Series(laprec[\"Total_2020_VAP\"])\n",
    "#     dempop = pd.Series(laprec[\"Total_2016-2020_Comp\"])\n",
    "\n",
    "#     # dpdf = pandas.concat([distpop,dempop], axis=1)\n",
    "#     # dpdf = dpdf.rename(columns={\"Total_2020_VAP\":\"temppop\", \"Total_2016-2020_Comp\":\"dempop\"})\n",
    "    \n",
    "#     laprec = laprec.merge(dpdf, how = \"left\", left_on=\"current\", right_on = dpdf.index)\n",
    "    \n",
    "#     # \"Weight Average\", percent of prec VAP of assigned Dist VAP\n",
    "#     laprec[\"wgtav\"] = laprec[\"Total_2020_VAP\"] / laprec[\"temppop\"] \n",
    "    \n",
    "#     # \"Dem Weight Average\", percent of prec Dem of assigned Dist Dems \n",
    "#     laprec['dwgt'] = laprec[\"Total_2016-2020_Comp\"] / laprec[\"dempop\"]\n",
    "    \n",
    "#     # \"BlackPct\" of Black VAP to Total VAP in Precinct\n",
    "#     laprec[\"BlkPct\"] = laprec[\"Black_2020_VAP\"] /  laprec[\"Total_2020_VAP\"]\n",
    "    \n",
    "#     # \"MinPct\" of Non-VAP to Total VAP in Precinct\n",
    "#     # Note! Hispanics are counted in White_2020_VAP!\n",
    "#     #       Should be sum of Hispanic, Black, Asian, Native, Pacific_2020_VAP\n",
    "#     laprec[\"MinPct\"] = (laprec[\"Total_2020_VAP\"] - laprec[\"White_2020_VAP\"] ) /  laprec[\"Total_2020_VAP\"\n",
    "    \n",
    "#     # \"DemPct\" of Composite Dems vs Total Voters in Precinct\n",
    "#     laprec[\"DemPct\"] = laprec[\"Dem_2016-2020_Comp\"] / laprec[\"Total_2016-2020_Comp\"] \n",
    "    \n",
    "#     # Produce weighted average for each Precinct                              \n",
    "#     laprec[\"BlkPctW\"] = laprec[\"BlkPct\"] * laprec[\"wgtav\"]\n",
    "#     laprec[\"MinPctW\"] = laprec[\"MinPct\"] * laprec[\"wgtav\"]\n",
    "#     laprec[\"DemPctW\"] = laprec[\"DemPct\"] * laprec[\"dwgt\"]\n",
    "    \n",
    "#     # Sum Each to Produce Percents\n",
    "#     DistDemPct = laprec.groupby([\"current\"])[\"DemPctW\"].sum()\n",
    "#     DistMinPct = laprec.groupby([\"current\"])[\"MinPctW\"].sum()\n",
    "#     DistBlkPct = laprec.groupby([\"current\"])[\"BlkPctW\"].sum()\n",
    "    \n",
    "#     DistDemPct = pandas.concat([DistDemPct, DistMinPct, DistBlkPct], axis=1)\n",
    "    \n",
    "#     DistDemPctD = DistDemPct.to_dict()\n",
    "    \n",
    "#     findict = {partnum: DistDemPctD}\n",
    "    \n",
    "#     del(laprec[\"temppop\"])\n",
    "#     del(laprec[\"dempop\"])\n",
    "    \n",
    "#     # Produces dictionary where key is partnumer and value is dictionary with Dem, Min and Blk percentages.\n",
    "#     return findict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain-Run Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_dists(percents, lothresh, hithresh):  \n",
    "        perc_list = [True if (lothresh <= dist <= hithresh) else False for dist in percents]\n",
    "        return sum(perc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trackers\n",
    "\n",
    "Mean_Median = pd.DataFrame(columns = [\"ID\", *ElectionNames]) # mms\n",
    "Efficiency_Gap = pd.DataFrame(columns = [\"ID\", *ElectionNames]) # egs\n",
    "Democratic_Wins = pd.DataFrame(columns = [\"ID\", *ElectionNames]) # hmss\n",
    "Partisan_Gini = pd.DataFrame(columns = [\"ID\", *ElectionNames]) # pgs\n",
    "Partisan_Bias = pd.DataFrame(columns = [\"ID\", *ElectionNames]) # pbs\n",
    "# VOTES = pd.DataFrame...\n",
    "\n",
    "trackercolumns = ([\"ID\",\n",
    "                   \"splits\", # splits\n",
    "                   \"dem_swings\", # dct\n",
    "                   \"dem_maj\", # dem\n",
    "                   \"maj_min\", # mmct\n",
    "                   \"cut_vec\"]) # Cut Edges \n",
    "\n",
    "Tracker = pd.DataFrame(columns = trackercolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partnum, part in enumerate(senchain.with_progress_bar()):\n",
    "\n",
    "    tracker_dict = {\"ID\": partnum}\n",
    "    # Splits\n",
    "    \n",
    "    splits = num_splits(part)\n",
    "    # Count of Democratic Swing Dists\n",
    "    dct = number_of_dists(part[\"Comp_Dems\"].percents(\"Democrat\"),.45,.55)\n",
    "    # Count of Democratic Maj Dists\n",
    "    dem = number_of_dists(part[\"Comp_Dems\"].percents(\"Democrat\"),.5,1.00)\n",
    "    # Count of Minority Maj Dists\n",
    "    mmct = number_of_dists(part[\"Min_VAP_20\"].percents('Minority'),.45,.55)\n",
    "    # Number of Cut Edges\n",
    "    cut_vec = (len(part[\"cut_edges\"]))\n",
    "        \n",
    "    tracker_dict.update({\"splits\": splits, \"dem_swings\": dct, \"dem_maj\": dem, \"maj_min\":mmct})\n",
    "    Tracker.append(tracker_dict, ignore_index=True)\n",
    "    \n",
    "    if dem >= 9 and mmct >= 9 and dct >= 5:\n",
    "        \n",
    "        # Extract Partition Assignment Dict\n",
    "        # Add GEOID20\n",
    "        asgn_dict = dict(part.assignment)\n",
    "        asgn_dict = {key:[asgn_dict[key], part.graph.nodes[key][\"GEOID20\"]]  for key in asgn_dict.keys()}\n",
    "        \n",
    "        # Create Partition Dataframe\n",
    "        # Name Columns, Set Index\n",
    "        # Save File\n",
    "        asgn_df = pd.DataFrame.from_dict(  asgn_dict, orient='index').reset_index()\n",
    "        asgn_df = asgn_df.rename({'index':'Node', 0:'Assignment', 1:'GEOID20'}, axis = 1).set_index(\"Node\")\n",
    "        sensdf.to_csv(PASSIGN_FILE.format(partnum)) \n",
    "    \n",
    "        ## Update Trackers ##\n",
    "        # One way to do it with dict comprehensions\n",
    "        # mms = {election: mean_median(part[election]) for election in ElectionNames}.update({\"ID\": partnum})\n",
    "        \n",
    "        mms = {\"ID\": partnum}\n",
    "        egs = {\"ID\": partnum}\n",
    "        pgs = {\"ID\": partnum}\n",
    "        pbs = {\"ID\": partnum}\n",
    "        hmss = {\"ID\": partnum}\n",
    "    \n",
    "        for election in ElectionNames:\n",
    "            # votes[elect].append(sorted(part[election_names[elect]].percents(\"Democratic\")))\n",
    "            mms.update({election: mean_median(part[election])})\n",
    "            egs.update({election: efficiency_gap(part[election])})\n",
    "            pgs.update({election: partisan_gini(part[election])})\n",
    "            pbs.update({election: partisan_bias(part[election])})\n",
    "            hmss.update({election: part[election].wins(\"Democratic\")})\n",
    "            \n",
    "        Mean_Median.append(mms)\n",
    "        Efficiency_Gap.append(egs)\n",
    "        Democratic_Wins.append(pgs)\n",
    "        Partisan_Gini.append(pbs)\n",
    "        Partisan_Bias.append(hmss)\n",
    "            \n",
    "        print(partnum, mmct, dem, dct,\"!!!!!\")\n",
    "    # else:\n",
    "        # print(partnum, mmct,dem, dct)\n",
    "           \n",
    "Tracker.to_csv(\"G:\\\\My Drive\\\\SFK Maps\\\\Final Chain Data\\\\Senate\\\\Partitions\\\\tracker.txt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Edited Original Chain-Run Block\n",
    "\n",
    "# pop_vec = [] # sorted(list(part[\"population\"].values()))\n",
    "# cut_vec = [] # len(part[\"cut_edges\"])\n",
    "# votes = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "# mms = [] # mean_median\n",
    "# egs = [] # efficiency_gap\n",
    "# hmss = [] # part[election_names[elect]].wins(\"Democratic\")\n",
    "# pgs =[] # partisan_gini\n",
    "# pbs = [] # partisan_bias\n",
    "# splits = [] # num_splits\n",
    "# pcents = [] # percmetrics accumulation\n",
    "\n",
    "# f=  open(\"G:\\\\My Drive\\\\SFK Maps\\\\Final Chain Data\\\\Senate\\\\Partitions\\\\tracker.txt\", \"a+\")\n",
    "\n",
    "# # partnum is id of each new Partition \n",
    "# # part is each new partition \n",
    "# # use with_progress_bar() from tqdm \n",
    "\n",
    "# for partnum, part in enumerate(senchain.with_progress_bar()):\n",
    "        \n",
    "    \n",
    "#     percd =  percmetrics(partnum,part)\n",
    "    \n",
    "#     dct = 0 # Count of Democratic Swing Dists on DemPctW\n",
    "#     mmct = 0 # Count of Minority Maj Dists on MinPctW\n",
    "#     dem = 0 # Count of Democratic Maj Dists on DemPctW\n",
    "    \n",
    "    \n",
    "#     for key in percd[partnum]['DemPctW']:\n",
    "#         if percd[partnum]['DemPctW'][key] >= 0.5:\n",
    "#             dem += 1\n",
    "#         if 0.45 <= percd[partnum]['DemPctW'][key] <= 0.55:\n",
    "#             dct += 1\n",
    "                \n",
    "#     for key in percd[partnum]['MinPctW']:\n",
    "#         if percd[partnum]['MinPctW'][key] >= 0.50:\n",
    "#             mmct += 1\n",
    "    \n",
    "#     # If more than 9 majority Dem, 9 min maj dists and 5 swing dists\n",
    "#     if dem >= 9 and mmct >= 9 and dct >= 5 :\n",
    "#         pcents.append(percd) # add percmetrics to pcents\n",
    "#         sens = [] # new list of sens\n",
    "        \n",
    "#         # Create Sens List for \n",
    "#         # for each node\n",
    "#         g = list(part.graph.nodes) \n",
    "#         for y in g:\n",
    "#             tt = [] # new tt list \n",
    "#             h = part.assignment[y] # h is assignment of node \n",
    "#             tt.append(y) # create [y, h]\n",
    "#             tt.append(h)\n",
    "#             sens.append(tt) # append [y, h] assignment list\n",
    "        \n",
    "        \n",
    "#         # save sensdf to file\n",
    "#         sensdf = pandas.DataFrame(sens)\n",
    "#         sensdf.to_csv(PASSIGN_FILE.format(partnum)) \n",
    "    \n",
    "#         splits.append(num_splits(part))\n",
    "    \n",
    "#         pop_vec.append(sorted(list(part[\"population\"].values())))\n",
    "#         cut_vec.append(len(part[\"cut_edges\"]))\n",
    "        \n",
    "#         # create new arrays in these tracker lists\n",
    "#         mms.append([])\n",
    "#         egs.append([])\n",
    "#         hmss.append([])\n",
    "#         pgs.append([])\n",
    "#         pbs.append([])\n",
    "        \n",
    "#         # for each election, add information \n",
    "#         for elect in range(num_elections):\n",
    "#             votes[elect].append(sorted(part[election_names[elect]].percents(\"Democratic\")))\n",
    "#             mms[-1].append(mean_median(part[election_names[elect]]))\n",
    "#             egs[-1].append(efficiency_gap(part[election_names[elect]]))\n",
    "#             pgs[-1].append(partisan_gini(part[election_names[elect]]))\n",
    "#             pbs[-1].append(partisan_bias(part[election_names[elect]]))\n",
    "#             hmss[-1].append(part[election_names[elect]].wins(\"Democratic\"))\n",
    "#         print(partnum, mmct, dem, dct,\"!!!!!\")\n",
    "#         f.write(str(partnum) +\" \"+ str(mmct) +\" \"+ str(dem) +\" \"+ str(dct)+\" \"+ \"\\n\")\n",
    "#     else:\n",
    "#         print(partnum, mmct,dem, dct)\n",
    "        \n",
    "# f.close()\n",
    "\n",
    "# # In[6]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7c64bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add suffix to column names\n",
    "mmspd = Mean_Median.rename(columns = {c:f\"{c}_mms\" for c in Mean_median.columns})\n",
    "\n",
    "# Etc...\n",
    "egspd = Efficiency_Gap \n",
    "hmsspd = Democratic_Wins\n",
    "pgspd = Partisan_Gini\n",
    "pbspd = Partisan_Bias\n",
    "spldpd = Tracker[[\"ID\",\"Splits\"]]\n",
    "\n",
    "\n",
    "# mmspd = pandas.DataFrame(mms)\n",
    "# egspd = pandas.DataFrame(egs)\n",
    "# pgspd = pandas.DataFrame(pgs)\n",
    "# pbspd = pandas.DataFrame(pbs)\n",
    "# hmsspd = pandas.DataFrame(hmss)\n",
    "# splpd = pandas.DataFrame(splits)\n",
    "# compctpd = pandas.DataFrame(compct) # No compct in original\n",
    "\n",
    "# mmspd = mmspd.rename(columns={0: \"20Pres_mms\",1: \"1Gov_mms\",2: \"19AG_mms\",3: \"19Gov_1_mms\",4: \"16Pres_mms\",5: \"16sen_mms\",6: \"16_sen_1_mms\"})\n",
    "# pgspd = pgspd.rename(columns={0: \"20Pres_pgs\",1: \"19Gov_pgs\",2: \"19AG_pgs\",3: \"19Gov_1_pgs\",4: \"16Pres_pgs\",5: \"16sen_pgs\",6: \"16_sen_1_pgs\"})\n",
    "# pbspd = pbspd.rename(columns={0: \"20Pres_pbs\",1: \"19Gov_pbs\",2: \"19AG_pbs\",3: \"19Gov_1_pbs\",4: \"16Pres_pbs\",5: \"16sen_pbs\",6: \"16_sen_1_pbs\"})\n",
    "# egspd = mmspd.rename(columns={0: \"20Pres_egs\",1: \"19Gov_egs\",2: \"19AG_egs\",3: \"19Gov_1_egs\",4: \"16Pres_egs\",5: \"16sen_egs\",6: \"16_sen_1_egs\"})\n",
    "# hmsspd = hmsspd.rename(columns={0: \"20Pres_hmss\",1: \"19Gov_hmss\",2: \"19AG_hmss\",3: \"19Gov_1_hmss\",4: \"16Pres_hmss\",5: \"16sen_hmss\",6: \"16_sen_1_hmss\"})\n",
    "# splpd = splpd.rename(columns={0: \"ParishSplits\"})\n",
    "\n",
    "# findf = pandas.concat([compctpd, mmspd,hmsspd,pgspd,pbspd,splpd],axis = 1)\n",
    "# findf = findf.rename(columns={0: \"ChainNum\", 1: \"CompDist\",2: \"DemMaj\",3: \"NonPckedBlck\",4: \"BlckMaj\",5: \"NonPckedMM\",6: \"MM\"})\n",
    "\n",
    "# #findf.to_csv(\"G:\\My Drive\\SFK Maps\\Final Chain Data\\lasen.csv\")\n",
    "# #laprec.to_csv(\"G:\\My Drive\\SFK Maps\\Final Chain Data\\laprec.csv\")\n",
    "# findf.to_csv(\"G:\\\\My Drive\\\\SFK Maps\\\\Final Chain Data\\\\Senate\\\\lasen.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
